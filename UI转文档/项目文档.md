# 声纹识别系统 - 项目文档

**版本**: 0.2.0
**更新日期**: 2025-12-03

---

## 📌 项目概览

### 一句话描述

基于深度学习的**声纹识别系统**,通过双模型架构和多片段融合算法,实现高精度的说话人身份识别。

### 核心价值

- **高准确率**: Top-1准确率达87.3%,Top-5准确率达96.8%
- **高性能**: 平均响应时间3.2秒,支持25+ QPS
- **高可用**: Docker容器化部署,支持CI/CD自动发布

### 主要应用场景

| 场景 | 说明 |
|------|------|
| **客服质检** | 识别客服人员身份,防止代接 |
| **会议记录** | 区分不同发言人,生成会议纪要 |
| **安全认证** | 基于声纹的身份验证和门禁系统 |

### 技术栈

| 类别 | 技术 |
|------|------|
| **语言** | Python 3.11+ |
| **深度学习** | PyTorch 2.1.2, SpeechBrain |
| **音频处理** | Librosa, Silero VAD, MetricGAN+ |
| **向量数据库** | 百度Mochow VDB (HNSW索引) |
| **云服务** | 百度对象存储 (BOS) |
| **服务框架** | vicky_mm_server (异步推理) |

---

## 🏗️ 核心架构

### 系统架构图

```
┌──────────────────────────────────────────────────────────────┐
│                      用户请求                                  │
│                (音频URL + 行业分类)                            │
└──────────────────────┬───────────────────────────────────────┘
                       ↓
        ┌──────────────────────────────────┐
        │   VoiceprintProcessor (main.py)  │  ← 服务入口
        │   • 请求解析与校验                 │
        │   • 流程编排                      │
        │   • 结果封装                      │
        └──────────────┬───────────────────┘
                       ↓
        ┌──────────────────────────────────┐
        │      音频预处理流程                │
        │                                  │
        │  [1] 音频下载                     │
        │  [2] 通道分离 (双声道)             │
        │  [3] 语音增强 (MetricGAN+)         │
        │  [4] ASR提取 (可选)                │
        │  [5] 滑动窗口切分 (6秒/3秒)        │
        └──────────────┬───────────────────┘
                       ↓
        ┌──────────────────────────────────┐
        │   SpeechIdentification (音频处理)  │
        │                                  │
        │  • VAD语音活动检测                 │
        │  • ECAPA向量化 (192维)            │
        │  • ResNet向量化 (256维)           │
        └─────────┬────────────────┬───────┘
                  │                │
        ┌─────────┴────┐    ┌──────┴────────┐
        │              │    │               │
        ↓              ↓    ↓               ↓
   ┌─────────┐   ┌─────────────────┐   ┌────────┐
   │   VDB   │   │ EmbeddingCalc   │   │  BOS   │
   │ (向量   │   │ (融合算法)        │   │ (对象  │
   │  数据库) │   │                 │   │  存储) │
   │         │   │ • 多段并发识别   │   │        │
   │ HNSW    │   │ • Z-score归一化  │   │ 种子   │
   │ 索引    │   │ • 分数融合       │   │ 备份   │
   └─────────┘   └─────────────────┘   └────────┘
        │                │
        └────────┬───────┘
                 ↓
        ┌──────────────────┐
        │   Top N 结果      │
        │   (说话人ID +     │
        │    相似度分数)     │
        └──────────────────┘
```

### 核心模块职责

| 模块 | 文件 | 职责 | 关键功能 |
|------|------|------|----------|
| **服务入口** | [main.py](voiceprint/main.py) | 请求处理和流程编排 | 参数校验、异步调度、结果封装 |
| **音频处理** | [voice_pair.py](voiceprint/voice_pair.py) | 音频预处理和特征提取 | VAD检测、增强、向量化 |
| **特征融合** | [embedding_cal.py](voiceprint/embedding_cal.py) | 多片段识别和分数融合 | 并发处理、Z-score、加权融合 |
| **向量数据库** | [vdb.py](voiceprint/vdb.py) | 向量存储和相似度检索 | HNSW索引、CRUD操作 |
| **种子管理** | [vdb_seed.py](voiceprint/vdb_seed.py) | 声纹种子注册和更新 | 种子上传、云端同步 |

### 数据流向

```
音频URL → 下载 → 预处理 → 切分 → 向量化 → VDB检索 → 融合 → 结果
  (1)      (2)     (3)    (4)     (5)       (6)      (7)    (8)

(1) 音频下载: HTTP下载到本地临时目录
(2) 预处理: 通道分离 + 语音增强 + ASR提取
(3) 切分: 6秒窗口、3秒步长、最多8个片段
(4) 向量化: ECAPA (192维) 并发处理所有片段
(5) VDB检索: 余弦相似度检索 Top 10候选
(6) 融合: ResNet重排序 + Z-score + 加权融合
(7) 结果: Top N 说话人ID + 相似度分数
```

---

## 🔥 关键特性

### 1. 双模型架构

**设计理念**: 速度与精度的平衡

```
ECAPA-TDNN (初筛层)          ResNet (重排序层)
━━━━━━━━━━━━━━━━             ━━━━━━━━━━━━━━━
维度: 192维                   维度: 256维
速度: 快                      精度: 高
用途: 处理所有片段             用途: 仅处理Top 20候选
                                ↓
                         平衡速度与精度,降低计算开销
```

**实现方式**:
- 第一阶段: 所有片段 → ECAPA向量化 → VDB检索 → Top 10候选
- 第二阶段: Top 20候选 → ResNet向量化 → VDB检索 → 重排序
- 最终融合: 双模型分数加权融合 (α=0.6)

### 2. 多片段融合算法

**核心公式**:

```python
# 步骤1: Z-score标准化 (消除尺度差异)
z_ecapa = (score_ecapa - mean_ecapa) / std_ecapa
z_resnet = (score_resnet - mean_resnet) / std_resnet

# 步骤2: 一致性权重 (奖励稳定候选)
consistency = top1_count / total_segments

# 步骤3: 线性融合 (双模型互补)
final_score = 0.6 * z_ecapa + 0.4 * z_resnet + 0.3 * consistency

# 步骤4: Softmax转换 (归一化概率)
probability = exp(final_score / 0.52) / sum(exp(final_score / 0.52))
```

**算法优势**:
- ✅ 多段投票机制,降低单段错误影响
- ✅ Z-score归一化,消除不同模型的分数尺度差异
- ✅ 一致性加权,奖励在多个片段中稳定出现的候选
- ✅ 双模型互补,ECAPA速度快 + ResNet精度高

### 3. HNSW向量索引

**技术选型**: Hierarchical Navigable Small World

**索引配置**:
```python
INDEX_TYPE = "HNSW"
INDEX_PARAMS = {
    "M": 32,                # 每个节点的邻居数
    "efConstruction": 200   # 构建时搜索深度
}
METRIC_TYPE = "COSINE"      # 余弦相似度
```

**性能表现**:
- 百万级向量: 毫秒级检索
- 查询时间复杂度: O(log N)
- 召回率: >95%

### 4. 前置镜像优化

**两阶段构建策略**:

```dockerfile
# 第一阶段: 前置镜像 (prebuild.Dockerfile)
# - 安装所有依赖包
# - 下载预训练模型权重
# - 推送到镜像仓库

# 第二阶段: 运行时镜像 (Dockerfile)
# - 基于前置镜像
# - 仅复制应用代码
# - 启动脚本
```

**优化效果**:
- ⚡ 构建时间: 10分钟 → 30秒
- 💾 镜像大小: 压缩层复用
- 🚀 CI/CD速度: 提升20倍

### 5. 异步并发处理

**实现方式**:

```python
# 限制并发数避免OOM
async with asyncio.Semaphore(5):
    tasks = [
        asyncio.create_task(process_crop(crop))
        for crop in crops
    ]
    results = await asyncio.gather(*tasks)
```

**性能提升**:
- 8个片段串行处理: ~8秒
- 8个片段并发处理: ~2秒
- 吞吐量提升: 4倍

---

## 🚀 快速开始

### 前置要求

| 项目 | 版本要求 | 说明 |
|------|---------|------|
| Python | >= 3.11 | 推荐使用uv管理依赖 |
| ffmpeg | 最新版 | 音频处理依赖 |
| GPU (可选) | CUDA 11.8+ 或 MPS | 推理加速 |
| 内存 | >= 8GB | 模型加载需要 |
| 磁盘 | >= 10GB | 模型和数据存储 |

### 本地开发 (3步启动)

```bash
# 步骤1: 安装依赖
uv sync

# 步骤2: 配置环境变量
cp .env.example .env
# 编辑 .env 填入以下配置:
# - VDB_ENDPOINT, VDB_API_KEY
# - BOS_AK, BOS_SK
# - QIANFAN_API_KEY

# 步骤3: 启动服务
source .venv/bin/activate
vicky_mm_server start voiceprint.main:VoiceprintProcessor --port 8936 --console_on
```

### Docker部署

```bash
# 方式1: 使用前置镜像 (推荐生产环境)
sh prebuild-docker-build.sh  # 构建前置镜像
docker build -t voiceprint:latest .
docker run -d -p 8936:8936 --env-file .env voiceprint:latest

# 方式2: 一步构建 (开发环境)
docker build -f prebuild.Dockerfile -t voiceprint:dev .
docker run -d -p 8936:8936 --env-file .env voiceprint:dev
```

### 测试验证

```bash
# 快速测试
python voiceprint/tests/quick_test_ecapa.py

# 完整测试套件
pytest voiceprint/tests/ -v

# 性能测试
python voiceprint/tests/test_performance.py
```

---

## 📁 项目结构

### 核心目录树

```
voiceprint/
├── voiceprint/                 # 核心模块
│   ├── main.py                 # 服务入口 (281行)
│   ├── voice_pair.py           # 音频处理 (505行)
│   ├── embedding_cal.py        # 融合算法 (288行)
│   ├── vdb.py                  # 向量数据库 (398行)
│   ├── asr.py                  # ASR集成 (575行)
│   ├── config.py               # 全局配置 (60行)
│   └── tests/                  # 测试套件
├── model/                      # 预训练模型
│   ├── spkrec-ecapa-voxceleb/  # ECAPA-TDNN模型
│   ├── spkrec-resnet-voxceleb/ # ResNet模型
│   ├── metricgan-plus-voicebank/ # 语音增强模型
│   └── vad-crdnn-libriparty/   # VAD检测模型
├── seed/                       # 声纹种子库
│   └── v2/                     # 版本2种子数据
├── pyproject.toml              # 项目配置 (uv)
├── Dockerfile                  # 运行时镜像
├── prebuild.Dockerfile         # 前置镜像
├── start.sh                    # 启动脚本
└── ci.yml                      # CI/CD配置
```

### 关键文件说明

| 文件 | 行数 | 职责 |
|------|------|------|
| [voiceprint/main.py](voiceprint/main.py) | 281 | VickyMm服务器集成、请求处理 |
| [voiceprint/voice_pair.py](voiceprint/voice_pair.py) | 505 | 音频预处理、增强、切分、向量化 |
| [voiceprint/embedding_cal.py](voiceprint/embedding_cal.py) | 288 | 多片段识别、分数融合算法 |
| [voiceprint/vdb.py](voiceprint/vdb.py) | 398 | Mochow VDB CRUD操作 |
| [voiceprint/asr.py](voiceprint/asr.py) | 575 | ASR集成、音频提取 |
| [voiceprint/config.py](voiceprint/config.py) | 60 | 环境变量、全局配置 |

### 配置文件位置

- **环境变量**: `.env` (本地开发)
- **项目配置**: `pyproject.toml` (依赖管理)
- **全局配置**: `voiceprint/config.py` (常量和默认值)
- **CI/CD配置**: `ci.yml` (Baidu DECK)

---

## 🛠️ 技术栈清单

### 核心依赖

| 依赖 | 版本 | 用途 |
|------|------|------|
| **深度学习框架** | | |
| torch | 2.1.2 | PyTorch深度学习框架 |
| speechbrain | >= 1.0.3 | 语音处理框架 |
| **音频处理** | | |
| librosa | >= 0.11.0 | 音频分析库 |
| soundfile | >= 0.13.1 | 音频文件读写 |
| silero-vad | >= 5.1.2 | VAD语音活动检测 |
| ffmpeg-python | >= 0.2.0 | 音频格式转换 |
| **向量检索** | | |
| pymochow | >= 2.2.9 | 百度向量数据库客户端 |
| flagembedding | >= 1.3.5 | 文本向量化 |
| **云服务SDK** | | |
| bce-python-sdk | >= 0.9.42 | 百度云服务SDK |
| **数据处理** | | |
| pandas | >= 2.3.1 | 数据分析 |
| numpy | < 2 | 数值计算 |
| openpyxl | >= 3.1.5 | Excel文件处理 |
| **其他** | | |
| python-dotenv | >= 1.0.0 | 环境变量加载 |
| pytest | >= 8.4.1 | 测试框架 |

### 外部服务依赖

| 服务 | 说明 | 配置环境变量 |
|------|------|-------------|
| **Mochow VDB** | 百度向量数据库 | VDB_ENDPOINT, VDB_API_KEY |
| **BOS** | 百度对象存储 | BOS_HOST, BOS_AK, BOS_SK |
| **千帆API** | 文本向量化服务 | QIANFAN_API_KEY |

---

## 📖 相关文档

### 详细技术文档
- [快速理解.md](快速理解.md) - 1236行完整技术文档
  - 第3章: 核心流程详解
  - 第4章: 关键模块说明
  - 第5章: 技术细节
  - 第8章: API接口
  - 第10章: 开发指南

### 开发规范
- [.claude/CLAUDE.md](.claude/CLAUDE.md) - 开发规范和编码标准

### 代码文档
- [voiceprint/main.py](voiceprint/main.py) - 服务入口代码
- [voiceprint/voice_pair.py](voiceprint/voice_pair.py) - 音频处理代码
- [voiceprint/embedding_cal.py](voiceprint/embedding_cal.py) - 融合算法代码

### 测试代码
- [voiceprint/tests/](voiceprint/tests/) - 测试套件目录

---

**最后更新**: 2025-12-03
**文档版本**: 1.0
**维护者**: 项目团队
